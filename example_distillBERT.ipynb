{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf57e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instalación de librerías necesarias\n",
    "# Descomenta la siguiente línea si no tienes instaladas estas librerías\n",
    "# !pip install transformers datasets torch scikit-learn pandas accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Verificar si hay GPU disponible (recomendado para entrenar BERT)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e37c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carga de Datos\n",
    "# Cargamos el dataset procesado\n",
    "file_path = './1. Detector_cyberbullying/cyberbullying_tweets_processed.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Usaremos 'tweet_text_clean' como entrada y 'cyberbullying_type' como etiqueta\n",
    "# Eliminamos filas con nulos en el texto limpio y en la etiqueta por seguridad\n",
    "df = df.dropna(subset=['tweet_text_clean', 'cyberbullying_type'])\n",
    "\n",
    "# Codificar las etiquetas de texto a números\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['cyberbullying_type'])\n",
    "\n",
    "# Guardar el mapeo de etiquetas para luego\n",
    "# Usamos range(len(le.classes_)) para evitar errores de transformación redundante\n",
    "label_map = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(\"Mapeo de etiquetas:\", label_map)\n",
    "\n",
    "# Separar textos y etiquetas\n",
    "texts = df['tweet_text_clean'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# División Train/Test (80% train, 20% test)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(train_texts)}\")\n",
    "print(f\"Datos de prueba: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00571fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenización\n",
    "# Cargamos el tokenizador pre-entrenado de DistilBERT\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenizamos los textos\n",
    "# truncation=True: Corta los tweets que sean más largos que el máximo permitido\n",
    "# padding=True: Rellena los tweets cortos para que todos tengan la misma longitud\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una clase Dataset compatible con PyTorch\n",
    "class CyberbullyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CyberbullyingDataset(train_encodings, train_labels)\n",
    "test_dataset = CyberbullyingDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Configuración del flujo de trabajo\n",
    "utilizar_pesos_guardados = True  # True: Intenta cargar modelo guardado. False: Fuerza re-entrenamiento.\n",
    "model_path = \"./modelo_ciberbullying_distilbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Lógica de Modelo (Cargar o Entrenar)\n",
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Definir dispositivo aquí también por seguridad\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Asegurar variables por si no se ejecutó la celda anterior\n",
    "if 'utilizar_pesos_guardados' not in locals():\n",
    "    utilizar_pesos_guardados = False\n",
    "if 'model_path' not in locals():\n",
    "    model_path = \"./modelo_ciberbullying_distilbert\"\n",
    "\n",
    "num_labels = len(label_map)\n",
    "model_loaded = False\n",
    "\n",
    "# Comprobar si existe el modelo guardado\n",
    "if utilizar_pesos_guardados and os.path.exists(model_path):\n",
    "    print(f\"Cargando modelo guardado desde '{model_path}'...\")\n",
    "    try:\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "        # model.to(device) # Eliminado: Trainer gestiona el dispositivo automáticamente\n",
    "        model_loaded = True\n",
    "        print(\"Modelo cargado exitosamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando el modelo: {e}. Se procederá a entrenar uno nuevo.\")\n",
    "        model_loaded = False\n",
    "\n",
    "if not model_loaded:\n",
    "    print(\"Iniciando configuración para entrenamiento de nuevo modelo...\")\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "    # model.to(device) # Eliminado: Trainer gestiona el dispositivo automáticamente\n",
    "    \n",
    "    # Configuración del Entrenamiento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {'accuracy': acc}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    print(\"Entrenando modelo...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(f\"Guardando modelo en '{model_path}'...\")\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "else:\n",
    "    # Si cargamos el modelo, instanciamos un Trainer para evaluación\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_eval_batch_size=64\n",
    "    )\n",
    "    \n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {'accuracy': acc}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Evaluación y Métricas\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Evaluando modelo...\")\n",
    "results = trainer.evaluate()\n",
    "print(\"Resultados de evaluación:\", results)\n",
    "\n",
    "# Predicciones sobre el conjunto de test\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "y_true = test_labels\n",
    "\n",
    "# Asegurar orden correcto de etiquetas para el reporte\n",
    "target_names = [k for k, v in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d94a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Gráficos y Estadísticas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Obtener los índices y nombres de las etiquetas en orden\n",
    "labels_indices = [v for k, v in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "labels_names = [k for k, v in sorted(label_map.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Generar matriz con etiquetas explícitas para asegurar el tamaño correcto\n",
    "# Esto evita errores si alguna clase no aparece en las predicciones o en el test set\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_indices)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels_names, \n",
    "            yticklabels=labels_names)\n",
    "plt.title('Matriz de Confusión - DistilBERT')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
