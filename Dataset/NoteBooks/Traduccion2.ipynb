{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91580cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.8.3)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\crist\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227948c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep-translator in c:\\users\\crist\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bb2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34895fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "\n",
    "translated = GoogleTranslator(source='auto', target='en').translate(\"Hola mundo\")\n",
    "print(translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43509aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "file_path = r\"C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\cyberbullying_tweets_limpio_idioma.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd660cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes después de eliminar idioma 'null': 47692\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas donde idioma == \"null\"\n",
    "df = df[df['idioma'] != \"null\"]\n",
    "print(f\"Filas restantes después de eliminar idioma 'null': {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "676addb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el traductor\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "# Función para traducir texto según idioma\n",
    "def traducir_texto(row):\n",
    "    try:\n",
    "        if row['idioma'] == \"english\":\n",
    "            return row['texto_limpio']\n",
    "        elif row['idioma'] == \"other\":\n",
    "            return translator.translate(row['texto_limpio'])\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al traducir: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ec78c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la traducción\n",
    "df[\"texto_traducido\"] = df.apply(traducir_texto, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f60494e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_path = r\"C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Archivo guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45a965fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>idioma</th>\n",
       "      <th>texto_traducido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes the test of god is that good or bad or ind...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>yes the test of god is that good or bad or ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>other</td>\n",
       "      <td>That's a school, it's not a place for bullies,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karma i hope it bites kat on the butt she is j...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>karma i hope it bites kat on the butt she is j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>everything but mostly my priest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rebecca black drops out of school due to bullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>rebecca black drops out of school due to bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the bully flushes on kd</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>the bully flushes on kd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ughhhh #mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>other</td>\n",
       "      <td>ughhhh #mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt turkish state has killed 241 children in la...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>rt turkish state has killed 241 children in la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>love that the best response to the hotcakes th...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>love that the best response to the hotcakes th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         texto_limpio cyberbullying_type  \\\n",
       "0   in other words #katandandre your food was crap...  not_cyberbullying   \n",
       "1   why is #aussietv so white #mkr #theblock #imac...  not_cyberbullying   \n",
       "2          a classy whore or more red velvet cupcakes  not_cyberbullying   \n",
       "3   meh p thanks for the heads up but not too conc...  not_cyberbullying   \n",
       "4   this is an isis account pretending to be a kur...  not_cyberbullying   \n",
       "5   yes the test of god is that good or bad or ind...  not_cyberbullying   \n",
       "6   itu sekolah ya bukan tempat bully ga jauh kaya...  not_cyberbullying   \n",
       "7   karma i hope it bites kat on the butt she is j...  not_cyberbullying   \n",
       "8                     everything but mostly my priest  not_cyberbullying   \n",
       "9   rebecca black drops out of school due to bullying  not_cyberbullying   \n",
       "10                                                NaN  not_cyberbullying   \n",
       "11                            the bully flushes on kd  not_cyberbullying   \n",
       "12                                        ughhhh #mkr  not_cyberbullying   \n",
       "13  rt turkish state has killed 241 children in la...  not_cyberbullying   \n",
       "14  love that the best response to the hotcakes th...  not_cyberbullying   \n",
       "\n",
       "     idioma                                    texto_traducido  \n",
       "0   english  in other words #katandandre your food was crap...  \n",
       "1   english  why is #aussietv so white #mkr #theblock #imac...  \n",
       "2   english         a classy whore or more red velvet cupcakes  \n",
       "3   english  meh p thanks for the heads up but not too conc...  \n",
       "4   english  this is an isis account pretending to be a kur...  \n",
       "5   english  yes the test of god is that good or bad or ind...  \n",
       "6     other  That's a school, it's not a place for bullies,...  \n",
       "7   english  karma i hope it bites kat on the butt she is j...  \n",
       "8   english                    everything but mostly my priest  \n",
       "9   english  rebecca black drops out of school due to bullying  \n",
       "10      NaN                                                NaN  \n",
       "11  english                            the bully flushes on kd  \n",
       "12    other                                        ughhhh #mkr  \n",
       "13  english  rt turkish state has killed 241 children in la...  \n",
       "14  english  love that the best response to the hotcakes th...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar 'tweets_trad.csv' en df para tener el original\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad.csv\")\n",
    "\n",
    "# Leer el archivo CSV traducido\n",
    "df2 = pd.read_csv(r\"C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad.csv\")\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "986ce313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas después de eliminar NaN en 'texto_limpio': 47426\n",
      "Número de filas originales:47692\n",
      "Número de filas eliminadas: 266\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las filas donde 'texto_limpio' es NaN\n",
    "df2 = df2.dropna(subset=['texto_limpio'])\n",
    "\n",
    "# Confirmar resultado\n",
    "print(f\"Número de filas después de eliminar NaN en 'texto_limpio': {len(df2)}\")\n",
    "print(f\"Número de filas originales:{len(df)}\")\n",
    "print(f\"Número de filas eliminadas: {len(df) - len(df2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e84f714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>idioma</th>\n",
       "      <th>texto_traducido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes the test of god is that good or bad or ind...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>yes the test of god is that good or bad or ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>other</td>\n",
       "      <td>That's a school, it's not a place for bullies,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karma i hope it bites kat on the butt she is j...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>karma i hope it bites kat on the butt she is j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>everything but mostly my priest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rebecca black drops out of school due to bullying</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>rebecca black drops out of school due to bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the bully flushes on kd</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>the bully flushes on kd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ughhhh #mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>other</td>\n",
       "      <td>ughhhh #mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt turkish state has killed 241 children in la...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>rt turkish state has killed 241 children in la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>love that the best response to the hotcakes th...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>english</td>\n",
       "      <td>love that the best response to the hotcakes th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>parem de fazer bullying comigo uhahuah bando d...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>other</td>\n",
       "      <td>stop bullying me uhahuah bunch of black people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         texto_limpio cyberbullying_type  \\\n",
       "0   in other words #katandandre your food was crap...  not_cyberbullying   \n",
       "1   why is #aussietv so white #mkr #theblock #imac...  not_cyberbullying   \n",
       "2          a classy whore or more red velvet cupcakes  not_cyberbullying   \n",
       "3   meh p thanks for the heads up but not too conc...  not_cyberbullying   \n",
       "4   this is an isis account pretending to be a kur...  not_cyberbullying   \n",
       "5   yes the test of god is that good or bad or ind...  not_cyberbullying   \n",
       "6   itu sekolah ya bukan tempat bully ga jauh kaya...  not_cyberbullying   \n",
       "7   karma i hope it bites kat on the butt she is j...  not_cyberbullying   \n",
       "8                     everything but mostly my priest  not_cyberbullying   \n",
       "9   rebecca black drops out of school due to bullying  not_cyberbullying   \n",
       "11                            the bully flushes on kd  not_cyberbullying   \n",
       "12                                        ughhhh #mkr  not_cyberbullying   \n",
       "13  rt turkish state has killed 241 children in la...  not_cyberbullying   \n",
       "14  love that the best response to the hotcakes th...  not_cyberbullying   \n",
       "15  parem de fazer bullying comigo uhahuah bando d...  not_cyberbullying   \n",
       "\n",
       "     idioma                                    texto_traducido  \n",
       "0   english  in other words #katandandre your food was crap...  \n",
       "1   english  why is #aussietv so white #mkr #theblock #imac...  \n",
       "2   english         a classy whore or more red velvet cupcakes  \n",
       "3   english  meh p thanks for the heads up but not too conc...  \n",
       "4   english  this is an isis account pretending to be a kur...  \n",
       "5   english  yes the test of god is that good or bad or ind...  \n",
       "6     other  That's a school, it's not a place for bullies,...  \n",
       "7   english  karma i hope it bites kat on the butt she is j...  \n",
       "8   english                    everything but mostly my priest  \n",
       "9   english  rebecca black drops out of school due to bullying  \n",
       "11  english                            the bully flushes on kd  \n",
       "12    other                                        ughhhh #mkr  \n",
       "13  english  rt turkish state has killed 241 children in la...  \n",
       "14  english  love that the best response to the hotcakes th...  \n",
       "15    other     stop bullying me uhahuah bunch of black people  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcd43003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "output_path = r\"C:\\\\Users\\\\crist\\\\Desktop\\\\CursoEOI-IA\\\\Chapter-5\\\\Proyecto_Samsung\\\\Dataset\\\\tweets_trad_clean.csv\"\n",
    "df2.to_csv(output_path, index=False)\n",
    "print(f\"Archivo guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5409c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\crist\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\crist\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\crist\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\crist\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.2-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/12.0 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.0 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.6/12.0 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 11.5 MB/s  0:00:01\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 9.8 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 12.8 MB/s  0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.4/110.9 MB 12.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 5.5/110.9 MB 13.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 8.4/110.9 MB 13.7 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 11.5/110.9 MB 13.6 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 14.2/110.9 MB 13.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 16.5/110.9 MB 13.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 18.6/110.9 MB 12.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 21.0/110.9 MB 12.4 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 22.8/110.9 MB 11.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 25.7/110.9 MB 12.0 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 27.8/110.9 MB 11.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 29.9/110.9 MB 11.7 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 32.2/110.9 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 34.3/110.9 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 36.7/110.9 MB 11.5 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 38.5/110.9 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 40.6/110.9 MB 11.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 42.5/110.9 MB 11.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 44.6/110.9 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 47.2/110.9 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.0/110.9 MB 11.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 50.9/110.9 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 52.7/110.9 MB 10.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 54.5/110.9 MB 10.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 56.4/110.9 MB 10.7 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 58.5/110.9 MB 10.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 60.0/110.9 MB 10.5 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 61.3/110.9 MB 10.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 62.9/110.9 MB 10.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 64.2/110.9 MB 10.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 65.3/110.9 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 66.6/110.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 67.6/110.9 MB 9.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 68.7/110.9 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 70.0/110.9 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 70.5/110.9 MB 9.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 71.6/110.9 MB 9.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 72.6/110.9 MB 9.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 73.1/110.9 MB 8.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 74.4/110.9 MB 8.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 75.5/110.9 MB 8.7 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 76.0/110.9 MB 8.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 77.3/110.9 MB 8.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 78.1/110.9 MB 8.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 79.2/110.9 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 80.5/110.9 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 81.0/110.9 MB 8.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 82.1/110.9 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 83.4/110.9 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 83.9/110.9 MB 7.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 84.7/110.9 MB 7.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 86.2/110.9 MB 7.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 86.8/110.9 MB 7.7 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 87.8/110.9 MB 7.7 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 89.1/110.9 MB 7.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 89.9/110.9 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 90.7/110.9 MB 7.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 91.8/110.9 MB 7.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 92.5/110.9 MB 7.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 93.3/110.9 MB 7.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 94.4/110.9 MB 7.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 95.2/110.9 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 95.9/110.9 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 97.0/110.9 MB 7.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 97.8/110.9 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 98.3/110.9 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 99.1/110.9 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 99.9/110.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 100.9/110.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 101.7/110.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 102.5/110.9 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.5/110.9 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 104.6/110.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 105.4/110.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 106.7/110.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 107.5/110.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.3/110.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.8/110.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.6/110.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/110.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 6.5 MB/s  0:00:17\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 3.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.3 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.4/6.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.9/6.3 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.2 MB/s  0:00:01\n",
      "Installing collected packages: sympy, safetensors, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.2\n",
      "\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "    Uninstalling sympy-1.13.2:\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ---------------------------------------- 0/7 [sympy]\n",
      "   ----- ---------------------------------- 1/7 [safetensors]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [torch]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------------- 7/7 [sentence-transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.7.0 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5faf2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar la librería sentence-transformers si no está instalada\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_package(\"sentence-transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96a74fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "81fd25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "file_path = r\"C:/Users/crist/Desktop/CursoEOI-IA/Chapter-5/Proyecto_Samsung/Dataset/tweets_trad_clean.csv\"\n",
    "df3 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fef7ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_traducido</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     texto_traducido cyberbullying_type\n",
       "0  in other words #katandandre your food was crap...  not_cyberbullying\n",
       "1  why is #aussietv so white #mkr #theblock #imac...  not_cyberbullying\n",
       "2         a classy whore or more red velvet cupcakes  not_cyberbullying\n",
       "3  meh p thanks for the heads up but not too conc...  not_cyberbullying\n",
       "4  this is an isis account pretending to be a kur...  not_cyberbullying"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar solo las columnas relevantes\n",
    "df3 = df3[[\"texto_traducido\", \"cyberbullying_type\"]]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "29a2061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"cyberbullying_type\" en una etiqueta binaria\n",
    "df3[\"label\"] = df3[\"cyberbullying_type\"].str.strip().str.lower().apply(\n",
    "    lambda x: 0 if x == \"not_cyberbullying\" else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5d1920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_traducido</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>teacher sets up new charity to tackle antigay ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>i can barely tolerate kat and andre katie and ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>people keep asking me about the stuff i posted...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>rape is realzvasiyana nema jokes about being d...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>you never saw any celebrity say anything like ...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>said the n word multiple times during her live...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>rt gotta bad bitch and she cant keep her cloth...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>milo isnt libertarian he did and interview wit...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>rt ucla womens law group libels chs then tries...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7961</th>\n",
       "      <td>says the guy that probably doesnt want to even...</td>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        texto_traducido cyberbullying_type  \\\n",
       "7855  teacher sets up new charity to tackle antigay ...  not_cyberbullying   \n",
       "7856  i can barely tolerate kat and andre katie and ...  not_cyberbullying   \n",
       "7857  people keep asking me about the stuff i posted...  not_cyberbullying   \n",
       "7858  rape is realzvasiyana nema jokes about being d...             gender   \n",
       "7859  you never saw any celebrity say anything like ...             gender   \n",
       "...                                                 ...                ...   \n",
       "7957  said the n word multiple times during her live...             gender   \n",
       "7958  rt gotta bad bitch and she cant keep her cloth...             gender   \n",
       "7959  milo isnt libertarian he did and interview wit...             gender   \n",
       "7960  rt ucla womens law group libels chs then tries...             gender   \n",
       "7961  says the guy that probably doesnt want to even...             gender   \n",
       "\n",
       "      label  \n",
       "7855      0  \n",
       "7856      0  \n",
       "7857      0  \n",
       "7858      1  \n",
       "7859      1  \n",
       "...     ...  \n",
       "7957      1  \n",
       "7958      1  \n",
       "7959      1  \n",
       "7960      1  \n",
       "7961      1  \n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3.reset_index(drop=True)\n",
    "df3.iloc[7855:7962]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "13f446fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['cyberbullying_type'] = df3['label']\n",
    "df3 = df3[[\"texto_traducido\", \"cyberbullying_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3179e417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_traducido</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre your food was crap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white #mkr #theblock #imac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     texto_traducido  cyberbullying_type\n",
       "0  in other words #katandandre your food was crap...                   0\n",
       "1  why is #aussietv so white #mkr #theblock #imac...                   0\n",
       "2         a classy whore or more red velvet cupcakes                   0\n",
       "3  meh p thanks for the heads up but not too conc...                   0\n",
       "4  this is an isis account pretending to be a kur...                   0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69527785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyberbullying_type\n",
      "1    39568\n",
      "0     7858\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47426"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df3[\"cyberbullying_type\"].value_counts())\n",
    "len(df3)\n",
    "\n",
    "# 1 ---> bullying\n",
    "# 0 ---> not bullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce07d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo Sentence-BERT\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Codificar los tweets usando Sentence-BERT\n",
    "X = model.encode(df3[\"texto_traducido\"].tolist())\n",
    "y = df3[\"cyberbullying_type\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "083d2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo de clasificación binaria (Logistic Regression)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "afaab0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d79e1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo:\n",
      "Accuracy: 0.86\n",
      "Precision: 0.88\n",
      "Recall: 0.96\n",
      "F1-score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las métricas de evaluación\n",
    "print(\"Resultados del modelo:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190c3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
